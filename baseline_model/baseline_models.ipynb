{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indirect-dollar",
   "metadata": {},
   "source": [
    "# Melanoma Classifier\n",
    "\n",
    "* Written for the Manning Live Project - [\"Semi supervised deep learning with gans for melanoma detection\"](https://liveproject.manning.com/project/146/29/semi-supervised-deep-learning-with-gans-for-melanoma-detection)\n",
    "* Contains 3 models - base line, augmented model and transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "middle-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "dataset_path = \"../Datasets/MelanomaDetection/\"\n",
    "train_dataset_path = dataset_path + \"labeled\"\n",
    "test_dataset_path = dataset_path + \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-poison",
   "metadata": {},
   "source": [
    "## Download data to Google Colab\n",
    "\n",
    "* Download data from Google Drive to local Google Colab disk\n",
    "* Allows the code to pickup the data as if it is running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/GDrive')\n",
    "\n",
    "# Adjust data set path to match where the data has been loaded\n",
    "dataset_path = '/GDrive/MyDrive/Datasets/MelanomaDetection/\"\n",
    "train_dataset_path = dataset_path + \"labeled\"\n",
    "test_dataset_path = dataset_path + \"test\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-abraham",
   "metadata": {},
   "source": [
    "## Allow it to run on the GPU\n",
    "\n",
    "* Code below detects if a GPU is available - if it is will run model on GPU\n",
    "* Code currently does not run on a GPU as apply_ is not supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fewer-electronics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook is currently running on the CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   print(\"Notebook is configured to run on the GPU!\")\n",
    "else:\n",
    "   print(\"Notebook is currently running on the CPU.\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-spending",
   "metadata": {},
   "source": [
    "## Dataloading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technological-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(batch_size, train_transform, test_transform):\n",
    "    train_dataset = MelanomaDataset(extract_label, train_dataset_path, transform=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = MelanomaDataset(extract_label, test_dataset_path, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def array_to_dictionary(array):\n",
    "    return {k: v for k, v in enumerate(array)}\n",
    "\n",
    "\n",
    "def extract_label(s):\n",
    "    if re.findall(\".*_1.jpg\", s):\n",
    "        return 1\n",
    "    elif re.findall(\".*_0.jpg\", s):\n",
    "        return 0\n",
    "    else:\n",
    "        raise RuntimeError(\"Invalid filename format: \" + s)\n",
    "\n",
    "\n",
    "class MelanomaDataset(Dataset):\n",
    "    \"\"\"Unlabelled Melanoma datasets\"\"\"\n",
    "\n",
    "    def __init__(self, label_extractor, dir_path, transform=None):\n",
    "        self.label_extractor = label_extractor\n",
    "        self.dir_path = dir_path\n",
    "        self.transform = transform\n",
    "        file_list = filter(lambda e: e != \".DS_Store\", os.listdir(dir_path))\n",
    "        self.file_list = array_to_dictionary(file_list)\n",
    "        self.len = len(self.file_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= self.len:\n",
    "            raise IndexError\n",
    "        else:\n",
    "            img_name = self.file_list[index]\n",
    "            full_img_name = os.path.join(self.dir_path, img_name)\n",
    "            image = Image.open(full_img_name)\n",
    "            # image = io.read_image(full_img_name)\n",
    "            # image = image.float()\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            result = {'name': img_name,\n",
    "                      'image': image}\n",
    "\n",
    "            if self.label_extractor:\n",
    "                result['label'] = self.label_extractor(img_name)\n",
    "\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-robin",
   "metadata": {},
   "source": [
    "## Training loop and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "local-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = itemgetter('image', 'label')(data)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            predicted = outputs.apply_(lambda e: 1 if e > 0.5 else 0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "\n",
    "    return correct / total, correct, total\n",
    "\n",
    "\n",
    "def train(model, criterion, train_loader, test_loader, lr, epochs, momentum):\n",
    "    # Each iteration of the loader serves up a pair (images, labels)\n",
    "    # The images are [64, 1, 28, 28] and the labels [64]\n",
    "    # The batch size is 64 images and the images are 28 x 28.\n",
    "    losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        print(\"\\nEpocs: \", e + 1)\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for data in train_loader:\n",
    "            images, labels = itemgetter('image', 'label')(data)\n",
    "            \n",
    "            # As data streams off the loader, push it onto the GPU so the\n",
    "            # calculation happens on the GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # zeros all the gradients of the weights\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels.float().unsqueeze(1))\n",
    "\n",
    "            # Calculates all the gradients via backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust weights based on the gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        loss = running_loss / len(train_loader)\n",
    "        test_accuracy, test_correct, test_total = validate(model, test_loader)\n",
    "        print(\"Loss: \", loss)\n",
    "        print(\"Test accuracy:\", test_accuracy, \", Correct: \", test_correct, \", Total:\", test_total)\n",
    "        losses.append(loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "    return losses, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-avatar",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ignored-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_model():\n",
    "    class Model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Model, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 24, (3, 3))\n",
    "            self.mp = nn.MaxPool2d((2, 2))\n",
    "            self.conv2 = nn.Conv2d(24, 48, (3, 3))\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.re = nn.ReLU()\n",
    "            self.l1 = nn.Linear(1728, 28)\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.l2 = nn.Linear(28, 1)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.re(x)\n",
    "            x = self.mp(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.re(x)\n",
    "            x = self.mp(x)\n",
    "\n",
    "            x = self.flatten(x)\n",
    "            x = self.l1(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.l2(x)\n",
    "            x = self.sigmoid(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_trained_model():\n",
    "    class PretrainedModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(PretrainedModel, self).__init__()\n",
    "            self.resnet = models.resnet18(pretrained=True)\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            self.linear = nn.Linear(1000, 1)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "            x = self.linear(x)\n",
    "            x = self.sigmoid(x)\n",
    "            return x\n",
    "        \n",
    "    model = PretrainedModel()\n",
    "    model = model.to(device)\n",
    "    return PretrainedModel()\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def scale_image(image):\n",
    "    return image * 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-sweet",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "\n",
    "* Simple CNN\n",
    "* Test accuracy around 73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "palestinian-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epocs:  1\n",
      "Loss:  18.509376491819108\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  2\n",
      "Loss:  9.840440162590571\n",
      "Test accuracy: 0.5133333333333333 , Correct:  308 , Total: 600\n",
      "\n",
      "Epocs:  3\n",
      "Loss:  0.6630214835916247\n",
      "Test accuracy: 0.705 , Correct:  423 , Total: 600\n",
      "\n",
      "Epocs:  4\n",
      "Loss:  0.5884216342653547\n",
      "Test accuracy: 0.66 , Correct:  396 , Total: 600\n",
      "\n",
      "Epocs:  5\n",
      "Loss:  0.6349138702665057\n",
      "Test accuracy: 0.555 , Correct:  333 , Total: 600\n",
      "\n",
      "Epocs:  6\n",
      "Loss:  0.5798675801072802\n",
      "Test accuracy: 0.6933333333333334 , Correct:  416 , Total: 600\n",
      "\n",
      "Epocs:  7\n",
      "Loss:  0.5631925719124931\n",
      "Test accuracy: 0.6283333333333333 , Correct:  377 , Total: 600\n",
      "\n",
      "Epocs:  8\n",
      "Loss:  0.5961653249604362\n",
      "Test accuracy: 0.7283333333333334 , Correct:  437 , Total: 600\n",
      "\n",
      "Epocs:  9\n",
      "Loss:  0.5702534828867231\n",
      "Test accuracy: 0.665 , Correct:  399 , Total: 600\n",
      "\n",
      "Epocs:  10\n",
      "Loss:  0.5593111557619912\n",
      "Test accuracy: 0.5333333333333333 , Correct:  320 , Total: 600\n",
      "\n",
      "Highest test accuracy: 0.7283333333333334\n",
      "Number of epocs: 8\n"
     ]
    }
   ],
   "source": [
    "def run_basic_model(batch_size):\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(12321)\n",
    "\n",
    "    lr = 0.001\n",
    "    momentum = 0\n",
    "    epochs = 10\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), scale_image])\n",
    "    train_loader, test_loader = data_loader(batch_size, transform, transform)\n",
    "    criterion = nn.BCELoss()\n",
    "    model = create_basic_model()\n",
    "\n",
    "    _, test_error = train(model, criterion, train_loader, test_loader, lr, epochs, momentum)\n",
    "\n",
    "    print()\n",
    "    print(\"Highest test accuracy:\", max(test_error))\n",
    "    print(\"Number of epocs:\", np.argmax(test_error) + 1)\n",
    "\n",
    "run_basic_model(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-guarantee",
   "metadata": {},
   "source": [
    "## Augmented model\n",
    "\n",
    "* Uses transforms on the input data to increase model accuracy\n",
    "* Highest accuracy around 76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ruled-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epocs:  1\n",
      "Loss:  41.45547103881836\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  2\n",
      "Loss:  47.32142857142857\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  3\n",
      "Loss:  51.339285714285715\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  4\n",
      "Loss:  48.28236280168806\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  5\n",
      "Loss:  53.62774058750698\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  6\n",
      "Loss:  48.66073226928711\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  7\n",
      "Loss:  51.52667454310826\n",
      "Test accuracy: 0.5 , Correct:  300 , Total: 600\n",
      "\n",
      "Epocs:  8\n",
      "Loss:  19.03887845788683\n",
      "Test accuracy: 0.52 , Correct:  312 , Total: 600\n",
      "\n",
      "Epocs:  9\n",
      "Loss:  0.9346129042761666\n",
      "Test accuracy: 0.6133333333333333 , Correct:  368 , Total: 600\n",
      "\n",
      "Epocs:  10\n",
      "Loss:  0.7425960898399353\n",
      "Test accuracy: 0.5216666666666666 , Correct:  313 , Total: 600\n",
      "\n",
      "Epocs:  11\n",
      "Loss:  0.6814041478293282\n",
      "Test accuracy: 0.5516666666666666 , Correct:  331 , Total: 600\n",
      "\n",
      "Epocs:  12\n",
      "Loss:  0.5908729732036591\n",
      "Test accuracy: 0.5833333333333334 , Correct:  350 , Total: 600\n",
      "\n",
      "Epocs:  13\n",
      "Loss:  0.6021847469466073\n",
      "Test accuracy: 0.7116666666666667 , Correct:  427 , Total: 600\n",
      "\n",
      "Epocs:  14\n",
      "Loss:  0.6580721437931061\n",
      "Test accuracy: 0.67 , Correct:  402 , Total: 600\n",
      "\n",
      "Epocs:  15\n",
      "Loss:  0.5707482865878514\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  16\n",
      "Loss:  0.563454806804657\n",
      "Test accuracy: 0.6983333333333334 , Correct:  419 , Total: 600\n",
      "\n",
      "Epocs:  17\n",
      "Loss:  0.5909929147788456\n",
      "Test accuracy: 0.71 , Correct:  426 , Total: 600\n",
      "\n",
      "Epocs:  18\n",
      "Loss:  0.600566851241248\n",
      "Test accuracy: 0.57 , Correct:  342 , Total: 600\n",
      "\n",
      "Epocs:  19\n",
      "Loss:  0.5457775975976672\n",
      "Test accuracy: 0.5683333333333334 , Correct:  341 , Total: 600\n",
      "\n",
      "Epocs:  20\n",
      "Loss:  0.6056140916688102\n",
      "Test accuracy: 0.6683333333333333 , Correct:  401 , Total: 600\n",
      "\n",
      "Epocs:  21\n",
      "Loss:  0.5989459753036499\n",
      "Test accuracy: 0.655 , Correct:  393 , Total: 600\n",
      "\n",
      "Epocs:  22\n",
      "Loss:  0.6060438879898616\n",
      "Test accuracy: 0.665 , Correct:  399 , Total: 600\n",
      "\n",
      "Epocs:  23\n",
      "Loss:  0.5666154793330601\n",
      "Test accuracy: 0.7266666666666667 , Correct:  436 , Total: 600\n",
      "\n",
      "Epocs:  24\n",
      "Loss:  0.5623699511800494\n",
      "Test accuracy: 0.725 , Correct:  435 , Total: 600\n",
      "\n",
      "Epocs:  25\n",
      "Loss:  0.5641712546348572\n",
      "Test accuracy: 0.7166666666666667 , Correct:  430 , Total: 600\n",
      "\n",
      "Epocs:  26\n",
      "Loss:  0.5406372419425419\n",
      "Test accuracy: 0.615 , Correct:  369 , Total: 600\n",
      "\n",
      "Epocs:  27\n",
      "Loss:  0.5998115369251796\n",
      "Test accuracy: 0.6466666666666666 , Correct:  388 , Total: 600\n",
      "\n",
      "Epocs:  28\n",
      "Loss:  0.5394505219800132\n",
      "Test accuracy: 0.61 , Correct:  366 , Total: 600\n",
      "\n",
      "Epocs:  29\n",
      "Loss:  0.6587155631610325\n",
      "Test accuracy: 0.56 , Correct:  336 , Total: 600\n",
      "\n",
      "Epocs:  30\n",
      "Loss:  0.613557687827519\n",
      "Test accuracy: 0.6833333333333333 , Correct:  410 , Total: 600\n",
      "\n",
      "Epocs:  31\n",
      "Loss:  0.5449416296822684\n",
      "Test accuracy: 0.605 , Correct:  363 , Total: 600\n",
      "\n",
      "Epocs:  32\n",
      "Loss:  0.5668833255767822\n",
      "Test accuracy: 0.7066666666666667 , Correct:  424 , Total: 600\n",
      "\n",
      "Epocs:  33\n",
      "Loss:  0.5690486133098602\n",
      "Test accuracy: 0.7166666666666667 , Correct:  430 , Total: 600\n",
      "\n",
      "Epocs:  34\n",
      "Loss:  0.5260511083262307\n",
      "Test accuracy: 0.7016666666666667 , Correct:  421 , Total: 600\n",
      "\n",
      "Epocs:  35\n",
      "Loss:  0.5647640228271484\n",
      "Test accuracy: 0.5583333333333333 , Correct:  335 , Total: 600\n",
      "\n",
      "Epocs:  36\n",
      "Loss:  0.5892941866602216\n",
      "Test accuracy: 0.695 , Correct:  417 , Total: 600\n",
      "\n",
      "Epocs:  37\n",
      "Loss:  0.5324059171336037\n",
      "Test accuracy: 0.7 , Correct:  420 , Total: 600\n",
      "\n",
      "Epocs:  38\n",
      "Loss:  0.4632746619837625\n",
      "Test accuracy: 0.7033333333333334 , Correct:  422 , Total: 600\n",
      "\n",
      "Epocs:  39\n",
      "Loss:  0.5503914526530674\n",
      "Test accuracy: 0.705 , Correct:  423 , Total: 600\n",
      "\n",
      "Epocs:  40\n",
      "Loss:  0.5313764682837895\n",
      "Test accuracy: 0.705 , Correct:  423 , Total: 600\n",
      "\n",
      "Epocs:  41\n",
      "Loss:  0.6217588824885232\n",
      "Test accuracy: 0.525 , Correct:  315 , Total: 600\n",
      "\n",
      "Epocs:  42\n",
      "Loss:  0.6503118319170815\n",
      "Test accuracy: 0.695 , Correct:  417 , Total: 600\n",
      "\n",
      "Epocs:  43\n",
      "Loss:  0.5181859178202493\n",
      "Test accuracy: 0.7333333333333333 , Correct:  440 , Total: 600\n",
      "\n",
      "Epocs:  44\n",
      "Loss:  0.5699052682944706\n",
      "Test accuracy: 0.7316666666666667 , Correct:  439 , Total: 600\n",
      "\n",
      "Epocs:  45\n",
      "Loss:  0.5738200630460467\n",
      "Test accuracy: 0.6016666666666667 , Correct:  361 , Total: 600\n",
      "\n",
      "Epocs:  46\n",
      "Loss:  0.5123564558369773\n",
      "Test accuracy: 0.69 , Correct:  414 , Total: 600\n",
      "\n",
      "Epocs:  47\n",
      "Loss:  0.5082442547593798\n",
      "Test accuracy: 0.7283333333333334 , Correct:  437 , Total: 600\n",
      "\n",
      "Epocs:  48\n",
      "Loss:  0.5266896912029811\n",
      "Test accuracy: 0.6766666666666666 , Correct:  406 , Total: 600\n",
      "\n",
      "Epocs:  49\n",
      "Loss:  0.5339702878679548\n",
      "Test accuracy: 0.5783333333333334 , Correct:  347 , Total: 600\n",
      "\n",
      "Epocs:  50\n",
      "Loss:  0.5418226633753095\n",
      "Test accuracy: 0.6466666666666666 , Correct:  388 , Total: 600\n",
      "\n",
      "Epocs:  51\n",
      "Loss:  0.5046815659318652\n",
      "Test accuracy: 0.6433333333333333 , Correct:  386 , Total: 600\n",
      "\n",
      "Epocs:  52\n",
      "Loss:  0.5360979735851288\n",
      "Test accuracy: 0.6816666666666666 , Correct:  409 , Total: 600\n",
      "\n",
      "Epocs:  53\n",
      "Loss:  0.5321472244603294\n",
      "Test accuracy: 0.64 , Correct:  384 , Total: 600\n",
      "\n",
      "Epocs:  54\n",
      "Loss:  0.5192192239420754\n",
      "Test accuracy: 0.6766666666666666 , Correct:  406 , Total: 600\n",
      "\n",
      "Epocs:  55\n",
      "Loss:  0.4750971368380955\n",
      "Test accuracy: 0.685 , Correct:  411 , Total: 600\n",
      "\n",
      "Epocs:  56\n",
      "Loss:  0.5384706599371774\n",
      "Test accuracy: 0.5483333333333333 , Correct:  329 , Total: 600\n",
      "\n",
      "Epocs:  57\n",
      "Loss:  0.544982590845653\n",
      "Test accuracy: 0.7016666666666667 , Correct:  421 , Total: 600\n",
      "\n",
      "Epocs:  58\n",
      "Loss:  0.5191420785018376\n",
      "Test accuracy: 0.71 , Correct:  426 , Total: 600\n",
      "\n",
      "Epocs:  59\n",
      "Loss:  0.47949202571596417\n",
      "Test accuracy: 0.675 , Correct:  405 , Total: 600\n",
      "\n",
      "Epocs:  60\n",
      "Loss:  0.4758574536868504\n",
      "Test accuracy: 0.7283333333333334 , Correct:  437 , Total: 600\n",
      "\n",
      "Epocs:  61\n",
      "Loss:  0.5114329627582005\n",
      "Test accuracy: 0.7133333333333334 , Correct:  428 , Total: 600\n",
      "\n",
      "Epocs:  62\n",
      "Loss:  0.5475751204150063\n",
      "Test accuracy: 0.7266666666666667 , Correct:  436 , Total: 600\n",
      "\n",
      "Epocs:  63\n",
      "Loss:  0.4902818330696651\n",
      "Test accuracy: 0.7116666666666667 , Correct:  427 , Total: 600\n",
      "\n",
      "Epocs:  64\n",
      "Loss:  0.49525406530925203\n",
      "Test accuracy: 0.7333333333333333 , Correct:  440 , Total: 600\n",
      "\n",
      "Epocs:  65\n",
      "Loss:  0.5889995055539268\n",
      "Test accuracy: 0.6783333333333333 , Correct:  407 , Total: 600\n",
      "\n",
      "Epocs:  66\n",
      "Loss:  0.5052306141172137\n",
      "Test accuracy: 0.725 , Correct:  435 , Total: 600\n",
      "\n",
      "Epocs:  67\n",
      "Loss:  0.49822076303618296\n",
      "Test accuracy: 0.7433333333333333 , Correct:  446 , Total: 600\n",
      "\n",
      "Epocs:  68\n",
      "Loss:  0.4862621767180307\n",
      "Test accuracy: 0.6666666666666666 , Correct:  400 , Total: 600\n",
      "\n",
      "Epocs:  69\n",
      "Loss:  0.5457383649689811\n",
      "Test accuracy: 0.705 , Correct:  423 , Total: 600\n",
      "\n",
      "Epocs:  70\n",
      "Loss:  0.5145015461104256\n",
      "Test accuracy: 0.7366666666666667 , Correct:  442 , Total: 600\n",
      "\n",
      "Epocs:  71\n",
      "Loss:  0.47626863207135883\n",
      "Test accuracy: 0.6516666666666666 , Correct:  391 , Total: 600\n",
      "\n",
      "Epocs:  72\n",
      "Loss:  0.511414817401341\n",
      "Test accuracy: 0.71 , Correct:  426 , Total: 600\n",
      "\n",
      "Epocs:  73\n",
      "Loss:  0.4624727623803275\n",
      "Test accuracy: 0.735 , Correct:  441 , Total: 600\n",
      "\n",
      "Epocs:  74\n",
      "Loss:  0.46684197442872183\n",
      "Test accuracy: 0.6933333333333334 , Correct:  416 , Total: 600\n",
      "\n",
      "Epocs:  75\n",
      "Loss:  0.4703123612063272\n",
      "Test accuracy: 0.605 , Correct:  363 , Total: 600\n",
      "\n",
      "Epocs:  76\n",
      "Loss:  0.5557589914117541\n",
      "Test accuracy: 0.635 , Correct:  381 , Total: 600\n",
      "\n",
      "Epocs:  77\n",
      "Loss:  0.5060350043433053\n",
      "Test accuracy: 0.6866666666666666 , Correct:  412 , Total: 600\n",
      "\n",
      "Epocs:  78\n",
      "Loss:  0.48485090477125986\n",
      "Test accuracy: 0.7266666666666667 , Correct:  436 , Total: 600\n",
      "\n",
      "Epocs:  79\n",
      "Loss:  0.4761424320084708\n",
      "Test accuracy: 0.6433333333333333 , Correct:  386 , Total: 600\n",
      "\n",
      "Epocs:  80\n",
      "Loss:  0.47274202959878103\n",
      "Test accuracy: 0.7383333333333333 , Correct:  443 , Total: 600\n",
      "\n",
      "Epocs:  81\n",
      "Loss:  0.46005051902362276\n",
      "Test accuracy: 0.7283333333333334 , Correct:  437 , Total: 600\n",
      "\n",
      "Epocs:  82\n",
      "Loss:  0.47710793358939035\n",
      "Test accuracy: 0.6816666666666666 , Correct:  409 , Total: 600\n",
      "\n",
      "Epocs:  83\n",
      "Loss:  0.46526665346963064\n",
      "Test accuracy: 0.6916666666666667 , Correct:  415 , Total: 600\n",
      "\n",
      "Epocs:  84\n",
      "Loss:  0.5153275898524693\n",
      "Test accuracy: 0.7033333333333334 , Correct:  422 , Total: 600\n",
      "\n",
      "Epocs:  85\n",
      "Loss:  0.43923606617110117\n",
      "Test accuracy: 0.7233333333333334 , Correct:  434 , Total: 600\n",
      "\n",
      "Epocs:  86\n",
      "Loss:  0.455714362008231\n",
      "Test accuracy: 0.5633333333333334 , Correct:  338 , Total: 600\n",
      "\n",
      "Epocs:  87\n",
      "Loss:  0.5154699214867183\n",
      "Test accuracy: 0.7133333333333334 , Correct:  428 , Total: 600\n",
      "\n",
      "Epocs:  88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.45847053612981525\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  89\n",
      "Loss:  0.48150940452303204\n",
      "Test accuracy: 0.6266666666666667 , Correct:  376 , Total: 600\n",
      "\n",
      "Epocs:  90\n",
      "Loss:  0.44262742144720896\n",
      "Test accuracy: 0.7433333333333333 , Correct:  446 , Total: 600\n",
      "\n",
      "Epocs:  91\n",
      "Loss:  0.4783282790865217\n",
      "Test accuracy: 0.7366666666666667 , Correct:  442 , Total: 600\n",
      "\n",
      "Epocs:  92\n",
      "Loss:  0.4878224900790623\n",
      "Test accuracy: 0.7133333333333334 , Correct:  428 , Total: 600\n",
      "\n",
      "Epocs:  93\n",
      "Loss:  0.43952041012900217\n",
      "Test accuracy: 0.6966666666666667 , Correct:  418 , Total: 600\n",
      "\n",
      "Epocs:  94\n",
      "Loss:  0.43405922821589876\n",
      "Test accuracy: 0.6783333333333333 , Correct:  407 , Total: 600\n",
      "\n",
      "Epocs:  95\n",
      "Loss:  0.4981179450239454\n",
      "Test accuracy: 0.7366666666666667 , Correct:  442 , Total: 600\n",
      "\n",
      "Epocs:  96\n",
      "Loss:  0.4631384696279253\n",
      "Test accuracy: 0.7283333333333334 , Correct:  437 , Total: 600\n",
      "\n",
      "Epocs:  97\n",
      "Loss:  0.4252978669745581\n",
      "Test accuracy: 0.745 , Correct:  447 , Total: 600\n",
      "\n",
      "Epocs:  98\n",
      "Loss:  0.45692221181733267\n",
      "Test accuracy: 0.6616666666666666 , Correct:  397 , Total: 600\n",
      "\n",
      "Epocs:  99\n",
      "Loss:  0.4820983622755323\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  100\n",
      "Loss:  0.45623484679630827\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  101\n",
      "Loss:  0.4402646890708378\n",
      "Test accuracy: 0.73 , Correct:  438 , Total: 600\n",
      "\n",
      "Epocs:  102\n",
      "Loss:  0.4622179738112858\n",
      "Test accuracy: 0.6433333333333333 , Correct:  386 , Total: 600\n",
      "\n",
      "Epocs:  103\n",
      "Loss:  0.47105792590550016\n",
      "Test accuracy: 0.7266666666666667 , Correct:  436 , Total: 600\n",
      "\n",
      "Epocs:  104\n",
      "Loss:  0.4693315752914974\n",
      "Test accuracy: 0.705 , Correct:  423 , Total: 600\n",
      "\n",
      "Epocs:  105\n",
      "Loss:  0.473676004580089\n",
      "Test accuracy: 0.5616666666666666 , Correct:  337 , Total: 600\n",
      "\n",
      "Epocs:  106\n",
      "Loss:  0.46842662564345766\n",
      "Test accuracy: 0.715 , Correct:  429 , Total: 600\n",
      "\n",
      "Epocs:  107\n",
      "Loss:  0.42353702442986624\n",
      "Test accuracy: 0.7183333333333334 , Correct:  431 , Total: 600\n",
      "\n",
      "Epocs:  108\n",
      "Loss:  0.427142722266061\n",
      "Test accuracy: 0.6466666666666666 , Correct:  388 , Total: 600\n",
      "\n",
      "Epocs:  109\n",
      "Loss:  0.45732315523283823\n",
      "Test accuracy: 0.725 , Correct:  435 , Total: 600\n",
      "\n",
      "Epocs:  110\n",
      "Loss:  0.4387220697743552\n",
      "Test accuracy: 0.6933333333333334 , Correct:  416 , Total: 600\n",
      "\n",
      "Epocs:  111\n",
      "Loss:  0.44924486109188627\n",
      "Test accuracy: 0.7166666666666667 , Correct:  430 , Total: 600\n",
      "\n",
      "Epocs:  112\n",
      "Loss:  0.44705504179000854\n",
      "Test accuracy: 0.5666666666666667 , Correct:  340 , Total: 600\n",
      "\n",
      "Epocs:  113\n",
      "Loss:  0.5470659264496395\n",
      "Test accuracy: 0.7116666666666667 , Correct:  427 , Total: 600\n",
      "\n",
      "Epocs:  114\n",
      "Loss:  0.5292426688330514\n",
      "Test accuracy: 0.6283333333333333 , Correct:  377 , Total: 600\n",
      "\n",
      "Epocs:  115\n",
      "Loss:  0.4677764007023403\n",
      "Test accuracy: 0.6866666666666666 , Correct:  412 , Total: 600\n",
      "\n",
      "Epocs:  116\n",
      "Loss:  0.46098014286586214\n",
      "Test accuracy: 0.6983333333333334 , Correct:  419 , Total: 600\n",
      "\n",
      "Epocs:  117\n",
      "Loss:  0.44463215129716055\n",
      "Test accuracy: 0.7233333333333334 , Correct:  434 , Total: 600\n",
      "\n",
      "Epocs:  118\n",
      "Loss:  0.5074169210025242\n",
      "Test accuracy: 0.73 , Correct:  438 , Total: 600\n",
      "\n",
      "Epocs:  119\n",
      "Loss:  0.47678385036332266\n",
      "Test accuracy: 0.74 , Correct:  444 , Total: 600\n",
      "\n",
      "Epocs:  120\n",
      "Loss:  0.4450190280164991\n",
      "Test accuracy: 0.7533333333333333 , Correct:  452 , Total: 600\n",
      "\n",
      "Epocs:  121\n",
      "Loss:  0.4466418709073748\n",
      "Test accuracy: 0.7466666666666667 , Correct:  448 , Total: 600\n",
      "\n",
      "Epocs:  122\n",
      "Loss:  0.4640663777078901\n",
      "Test accuracy: 0.7183333333333334 , Correct:  431 , Total: 600\n",
      "\n",
      "Epocs:  123\n",
      "Loss:  0.43789322887148174\n",
      "Test accuracy: 0.6616666666666666 , Correct:  397 , Total: 600\n",
      "\n",
      "Epocs:  124\n",
      "Loss:  0.47517673884119305\n",
      "Test accuracy: 0.7383333333333333 , Correct:  443 , Total: 600\n",
      "\n",
      "Epocs:  125\n",
      "Loss:  0.46000173687934875\n",
      "Test accuracy: 0.715 , Correct:  429 , Total: 600\n",
      "\n",
      "Epocs:  126\n",
      "Loss:  0.44207110149519785\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  127\n",
      "Loss:  0.43906913910593304\n",
      "Test accuracy: 0.665 , Correct:  399 , Total: 600\n",
      "\n",
      "Epocs:  128\n",
      "Loss:  0.4651422436748232\n",
      "Test accuracy: 0.695 , Correct:  417 , Total: 600\n",
      "\n",
      "Epocs:  129\n",
      "Loss:  0.4065518102475575\n",
      "Test accuracy: 0.75 , Correct:  450 , Total: 600\n",
      "\n",
      "Epocs:  130\n",
      "Loss:  0.4801540161882128\n",
      "Test accuracy: 0.7283333333333334 , Correct:  437 , Total: 600\n",
      "\n",
      "Epocs:  131\n",
      "Loss:  0.4493396409920284\n",
      "Test accuracy: 0.7566666666666667 , Correct:  454 , Total: 600\n",
      "\n",
      "Epocs:  132\n",
      "Loss:  0.49235848018101286\n",
      "Test accuracy: 0.71 , Correct:  426 , Total: 600\n",
      "\n",
      "Epocs:  133\n",
      "Loss:  0.41090962290763855\n",
      "Test accuracy: 0.7516666666666667 , Correct:  451 , Total: 600\n",
      "\n",
      "Epocs:  134\n",
      "Loss:  0.4572121117796217\n",
      "Test accuracy: 0.7083333333333334 , Correct:  425 , Total: 600\n",
      "\n",
      "Epocs:  135\n",
      "Loss:  0.40485675420079914\n",
      "Test accuracy: 0.645 , Correct:  387 , Total: 600\n",
      "\n",
      "Epocs:  136\n",
      "Loss:  0.41296301995004925\n",
      "Test accuracy: 0.73 , Correct:  438 , Total: 600\n",
      "\n",
      "Epocs:  137\n",
      "Loss:  0.44276452490261625\n",
      "Test accuracy: 0.7216666666666667 , Correct:  433 , Total: 600\n",
      "\n",
      "Epocs:  138\n",
      "Loss:  0.45006545952388216\n",
      "Test accuracy: 0.6716666666666666 , Correct:  403 , Total: 600\n",
      "\n",
      "Epocs:  139\n",
      "Loss:  0.4440461908067976\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  140\n",
      "Loss:  0.4212777316570282\n",
      "Test accuracy: 0.75 , Correct:  450 , Total: 600\n",
      "\n",
      "Epocs:  141\n",
      "Loss:  0.4620196350983211\n",
      "Test accuracy: 0.6683333333333333 , Correct:  401 , Total: 600\n",
      "\n",
      "Epocs:  142\n",
      "Loss:  0.4181375056505203\n",
      "Test accuracy: 0.6283333333333333 , Correct:  377 , Total: 600\n",
      "\n",
      "Epocs:  143\n",
      "Loss:  0.4173772803374699\n",
      "Test accuracy: 0.7316666666666667 , Correct:  439 , Total: 600\n",
      "\n",
      "Epocs:  144\n",
      "Loss:  0.44004502466746737\n",
      "Test accuracy: 0.7033333333333334 , Correct:  422 , Total: 600\n",
      "\n",
      "Epocs:  145\n",
      "Loss:  0.4740404997553144\n",
      "Test accuracy: 0.715 , Correct:  429 , Total: 600\n",
      "\n",
      "Epocs:  146\n",
      "Loss:  0.38644848125321524\n",
      "Test accuracy: 0.7483333333333333 , Correct:  449 , Total: 600\n",
      "\n",
      "Epocs:  147\n",
      "Loss:  0.44074964949062895\n",
      "Test accuracy: 0.7433333333333333 , Correct:  446 , Total: 600\n",
      "\n",
      "Epocs:  148\n",
      "Loss:  0.4468501806259155\n",
      "Test accuracy: 0.5866666666666667 , Correct:  352 , Total: 600\n",
      "\n",
      "Epocs:  149\n",
      "Loss:  0.5039227690015521\n",
      "Test accuracy: 0.725 , Correct:  435 , Total: 600\n",
      "\n",
      "Epocs:  150\n",
      "Loss:  0.44696156467710224\n",
      "Test accuracy: 0.7566666666666667 , Correct:  454 , Total: 600\n",
      "\n",
      "Epocs:  151\n",
      "Loss:  0.4085134608404977\n",
      "Test accuracy: 0.6966666666666667 , Correct:  418 , Total: 600\n",
      "\n",
      "Epocs:  152\n",
      "Loss:  0.42204377480915617\n",
      "Test accuracy: 0.6383333333333333 , Correct:  383 , Total: 600\n",
      "\n",
      "Epocs:  153\n",
      "Loss:  0.4211182658161436\n",
      "Test accuracy: 0.7266666666666667 , Correct:  436 , Total: 600\n",
      "\n",
      "Epocs:  154\n",
      "Loss:  0.4134768077305385\n",
      "Test accuracy: 0.7466666666666667 , Correct:  448 , Total: 600\n",
      "\n",
      "Epocs:  155\n",
      "Loss:  0.4163536897727421\n",
      "Test accuracy: 0.6816666666666666 , Correct:  409 , Total: 600\n",
      "\n",
      "Epocs:  156\n",
      "Loss:  0.4700188083308084\n",
      "Test accuracy: 0.7083333333333334 , Correct:  425 , Total: 600\n",
      "\n",
      "Epocs:  157\n",
      "Loss:  0.43220448919704985\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  158\n",
      "Loss:  0.4118136167526245\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  159\n",
      "Loss:  0.4783713349274227\n",
      "Test accuracy: 0.7316666666666667 , Correct:  439 , Total: 600\n",
      "\n",
      "Epocs:  160\n",
      "Loss:  0.424621901341847\n",
      "Test accuracy: 0.7083333333333334 , Correct:  425 , Total: 600\n",
      "\n",
      "Epocs:  161\n",
      "Loss:  0.394325567143304\n",
      "Test accuracy: 0.6983333333333334 , Correct:  419 , Total: 600\n",
      "\n",
      "Epocs:  162\n",
      "Loss:  0.4144192934036255\n",
      "Test accuracy: 0.7433333333333333 , Correct:  446 , Total: 600\n",
      "\n",
      "Epocs:  163\n",
      "Loss:  0.4133950727326529\n",
      "Test accuracy: 0.72 , Correct:  432 , Total: 600\n",
      "\n",
      "Epocs:  164\n",
      "Loss:  0.4109052377087729\n",
      "Test accuracy: 0.715 , Correct:  429 , Total: 600\n",
      "\n",
      "Epocs:  165\n",
      "Loss:  0.42656603881290983\n",
      "Test accuracy: 0.6566666666666666 , Correct:  394 , Total: 600\n",
      "\n",
      "Epocs:  166\n",
      "Loss:  0.42119756766727995\n",
      "Test accuracy: 0.7366666666666667 , Correct:  442 , Total: 600\n",
      "\n",
      "Epocs:  167\n",
      "Loss:  0.3936821562903268\n",
      "Test accuracy: 0.725 , Correct:  435 , Total: 600\n",
      "\n",
      "Epocs:  168\n",
      "Loss:  0.46349178893225534\n",
      "Test accuracy: 0.62 , Correct:  372 , Total: 600\n",
      "\n",
      "Epocs:  169\n",
      "Loss:  0.4333607724734715\n",
      "Test accuracy: 0.7383333333333333 , Correct:  443 , Total: 600\n",
      "\n",
      "Epocs:  170\n",
      "Loss:  0.43825170397758484\n",
      "Test accuracy: 0.6533333333333333 , Correct:  392 , Total: 600\n",
      "\n",
      "Epocs:  171\n",
      "Loss:  0.492963297026498\n",
      "Test accuracy: 0.7233333333333334 , Correct:  434 , Total: 600\n",
      "\n",
      "Epocs:  172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.40792656796319143\n",
      "Test accuracy: 0.7216666666666667 , Correct:  433 , Total: 600\n",
      "\n",
      "Epocs:  173\n",
      "Loss:  0.4385403905596052\n",
      "Test accuracy: 0.7383333333333333 , Correct:  443 , Total: 600\n",
      "\n",
      "Epocs:  174\n",
      "Loss:  0.3593711129256657\n",
      "Test accuracy: 0.7116666666666667 , Correct:  427 , Total: 600\n",
      "\n",
      "Epocs:  175\n",
      "Loss:  0.41929927468299866\n",
      "Test accuracy: 0.75 , Correct:  450 , Total: 600\n",
      "\n",
      "Epocs:  176\n",
      "Loss:  0.4246256394045694\n",
      "Test accuracy: 0.7033333333333334 , Correct:  422 , Total: 600\n",
      "\n",
      "Epocs:  177\n",
      "Loss:  0.4149159405912672\n",
      "Test accuracy: 0.6583333333333333 , Correct:  395 , Total: 600\n",
      "\n",
      "Epocs:  178\n",
      "Loss:  0.43273715887750897\n",
      "Test accuracy: 0.75 , Correct:  450 , Total: 600\n",
      "\n",
      "Epocs:  179\n",
      "Loss:  0.4055129417351314\n",
      "Test accuracy: 0.71 , Correct:  426 , Total: 600\n",
      "\n",
      "Epocs:  180\n",
      "Loss:  0.4037867433258465\n",
      "Test accuracy: 0.6733333333333333 , Correct:  404 , Total: 600\n",
      "\n",
      "Epocs:  181\n",
      "Loss:  0.3779088258743286\n",
      "Test accuracy: 0.705 , Correct:  423 , Total: 600\n",
      "\n",
      "Epocs:  182\n",
      "Loss:  0.37598549681050436\n",
      "Test accuracy: 0.73 , Correct:  438 , Total: 600\n",
      "\n",
      "Epocs:  183\n",
      "Loss:  0.4114337648664202\n",
      "Test accuracy: 0.74 , Correct:  444 , Total: 600\n",
      "\n",
      "Epocs:  184\n",
      "Loss:  0.4443628745419638\n",
      "Test accuracy: 0.6833333333333333 , Correct:  410 , Total: 600\n",
      "\n",
      "Epocs:  185\n",
      "Loss:  0.4310627579689026\n",
      "Test accuracy: 0.7233333333333334 , Correct:  434 , Total: 600\n",
      "\n",
      "Epocs:  186\n",
      "Loss:  0.4413279380117144\n",
      "Test accuracy: 0.755 , Correct:  453 , Total: 600\n",
      "\n",
      "Epocs:  187\n",
      "Loss:  0.38900559289114817\n",
      "Test accuracy: 0.715 , Correct:  429 , Total: 600\n",
      "\n",
      "Epocs:  188\n",
      "Loss:  0.4024152713162558\n",
      "Test accuracy: 0.7266666666666667 , Correct:  436 , Total: 600\n",
      "\n",
      "Epocs:  189\n",
      "Loss:  0.42046775562422617\n",
      "Test accuracy: 0.7233333333333334 , Correct:  434 , Total: 600\n",
      "\n",
      "Epocs:  190\n",
      "Loss:  0.39171223981039865\n",
      "Test accuracy: 0.6483333333333333 , Correct:  389 , Total: 600\n",
      "\n",
      "Epocs:  191\n",
      "Loss:  0.4483250890459333\n",
      "Test accuracy: 0.7266666666666667 , Correct:  436 , Total: 600\n",
      "\n",
      "Epocs:  192\n",
      "Loss:  0.4063582250050136\n",
      "Test accuracy: 0.745 , Correct:  447 , Total: 600\n",
      "\n",
      "Epocs:  193\n",
      "Loss:  0.4401874840259552\n",
      "Test accuracy: 0.7183333333333334 , Correct:  431 , Total: 600\n",
      "\n",
      "Epocs:  194\n",
      "Loss:  0.4352873052869524\n",
      "Test accuracy: 0.735 , Correct:  441 , Total: 600\n",
      "\n",
      "Epocs:  195\n",
      "Loss:  0.3919276509966169\n",
      "Test accuracy: 0.7316666666666667 , Correct:  439 , Total: 600\n",
      "\n",
      "Epocs:  196\n",
      "Loss:  0.4298804828098842\n",
      "Test accuracy: 0.7466666666666667 , Correct:  448 , Total: 600\n",
      "\n",
      "Epocs:  197\n",
      "Loss:  0.44430595210620333\n",
      "Test accuracy: 0.6716666666666666 , Correct:  403 , Total: 600\n",
      "\n",
      "Epocs:  198\n",
      "Loss:  0.42890611716679167\n",
      "Test accuracy: 0.6983333333333334 , Correct:  419 , Total: 600\n",
      "\n",
      "Epocs:  199\n",
      "Loss:  0.4025852084159851\n",
      "Test accuracy: 0.7016666666666667 , Correct:  421 , Total: 600\n",
      "\n",
      "Epocs:  200\n",
      "Loss:  0.4336372911930084\n",
      "Test accuracy: 0.5733333333333334 , Correct:  344 , Total: 600\n",
      "\n",
      "Highest test accuracy: 0.7566666666666667\n",
      "Number of epocs: 131\n"
     ]
    }
   ],
   "source": [
    "def augmentation_transforms():\n",
    "    rotation = transforms.RandomChoice(\n",
    "        [transforms.RandomRotation([-3, 3]),\n",
    "         transforms.RandomRotation([87, 93]),\n",
    "         transforms.RandomRotation([177, 183]),\n",
    "         transforms.RandomRotation([267, 273])])\n",
    "\n",
    "    return transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomVerticalFlip(),\n",
    "                               rotation])\n",
    "\n",
    "\n",
    "def run_augmented_model(batch_size):\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(12321)\n",
    "\n",
    "    lr = 0.001\n",
    "    momentum = 0.2\n",
    "    epochs = 200\n",
    "\n",
    "    base_transform = transforms.Compose([transforms.ToTensor(), scale_image])\n",
    "    augmentation = augmentation_transforms()\n",
    "    preprocess = transforms.Compose([base_transform, augmentation])\n",
    "\n",
    "    train_loader, test_loader = data_loader(batch_size, preprocess, base_transform)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    model = create_basic_model()\n",
    "\n",
    "    _, test_error = train(model, criterion, train_loader, test_loader, lr, epochs, momentum)\n",
    "\n",
    "    print()\n",
    "    print(\"Highest test accuracy:\", max(test_error))\n",
    "    print(\"Number of epocs:\", np.argmax(test_error) + 1)\n",
    "    \n",
    "    \n",
    "run_augmented_model(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-baltimore",
   "metadata": {},
   "source": [
    "## Pretrained model\n",
    "\n",
    "* Starts with ResNet 18 model \n",
    "* Freezes the parameters\n",
    "* Adds a fully connected layer consisting of a single neuron and a sigmoid\n",
    "* Accuracy around 79-80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "silver-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epocs:  1\n",
      "Loss:  0.5716858293328967\n",
      "Test accuracy: 0.715 , Correct:  429 , Total: 600\n",
      "\n",
      "Epocs:  2\n",
      "Loss:  0.41775238939694\n",
      "Test accuracy: 0.7583333333333333 , Correct:  455 , Total: 600\n",
      "\n",
      "Epocs:  3\n",
      "Loss:  0.6201600474970681\n",
      "Test accuracy: 0.7883333333333333 , Correct:  473 , Total: 600\n",
      "\n",
      "Highest test accuracy: 0.7883333333333333\n",
      "Number of epocs: 3\n"
     ]
    }
   ],
   "source": [
    "def run_pretrained_model(batch_size):\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    base = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )])\n",
    "    augmentation = augmentation_transforms()\n",
    "    preprocess = transforms.Compose([base, augmentation])\n",
    "\n",
    "    train_loader, test_loader = data_loader(batch_size, preprocess, base)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    model = create_trained_model()\n",
    "\n",
    "    lr = 0.001\n",
    "    momentum = 0.9\n",
    "    epochs = 3\n",
    "\n",
    "    _, test_error = train(model, criterion, train_loader, test_loader, lr, epochs, momentum)\n",
    "\n",
    "    print()\n",
    "    print(\"Highest test accuracy:\", max(test_error))\n",
    "    print(\"Number of epocs:\", np.argmax(test_error) + 1)\n",
    "\n",
    "    \n",
    "run_pretrained_model(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-surfing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
